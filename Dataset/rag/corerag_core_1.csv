id,Parameter1,Parameter2,bnf,type
1,io.compression.codec.bzip2.library,mapreduce.map.output.compress.codec,mapreduce.map.output.compress.codec = 'org.apache.hadoop.io.compress.BZip2Codec' => io.compression.codec.bzip2.library != null,behavior
2,nfs.keytab.file,nfs.kerberos.principal,nfs.keytab.file != null => nfs.kerberos.principal != null,behavior
3,fs.adl.oauth2.access.token.provider,fs.adl.oauth2.credential,fs.adl.oauth2.access.token.provider != null => fs.adl.oauth2.credential != null,behavior
4,hadoop.security.kms.client.encrypted.key.cache.low-watermark,hadoop.security.kms.client.encrypted.key.cache.num.refill.threads,hadoop.security.kms.client.encrypted.key.cache.low-watermark < 0.3 => hadoop.security.kms.client.encrypted.key.cache.num.refill.threads = 2,behavior
5,ssl.server.keystore.location,ssl.server.keystore.type,ssl.server.keystore.location != null => ssl.server.keystore.type = ANY,behavior
6,ssl.server.truststore.location,ssl.client.truststore.location,ssl.server.truststore.location != null => ssl.client.truststore.location != null,behavior
7,zookeeper.znode.parent,hbase.zookeeper.session.timeout,"<Dependency> ::= <Variable> != ""null"" => <ConstraintItem> <Variable> = ""ANY""",behavior
8,hfile.block.index.cacheonwrite,hfile.block.cache.size,hfile.block.index.cacheonwrite = true => hfile.block.cache.size > [default..ANY],behavior
9,hadoop.security.crypto.jce.provider,hadoop.security.crypto.codec.classes.aes.ctr.nopadding,hadoop.security.crypto.jce.provider != null => hadoop.security.crypto.codec.classes.aes.ctr.nopadding != null,behavior
10,ipc.client.idlethreshold,ipc.client.connection.maxlifetime,ipc.client.idlethreshold > 0 => ipc.client.connection.maxlifetime > ipc.client.idlethreshold * 2,behavior
11,fs.adl.oauth2.client.id,fs.adl.oauth2.credential,fs.adl.oauth2.client.id != null => fs.adl.oauth2.credential != null,behavior
12,seq.io.sort.factor,io.sort.mb,seq.io.sort.factor > default => io.sort.mb > default,behavior
13,hadoop.security.groups.cache.secs,hadoop.security.groups.cache.background.reload.threads,hadoop.security.groups.cache.secs > 0 => hadoop.security.groups.cache.background.reload.threads > 1,behavior
14,fs.s3a.connection.timeout,fs.s3a.attempts.maximum,fs.s3a.connection.timeout > 30 => fs.s3a.attempts.maximum in {{3..5}},behavior
15,s3.bytes-per-checksum,rgw_multipart_part_size,s3.bytes-per-checksum > 0 => rgw_multipart_part_size % s3.bytes-per-checksum = 0,behavior
16,zookeeper.session.timeout,zookeeper.recovery.retry.maxsleeptime,zookeeper.session.timeout != null => zookeeper.recovery.retry.maxsleeptime = 60000,behavior
17,fs.s3a.max.total.tasks,fs.s3a.multipart.threshold,fs.s3a.max.total.tasks > default => fs.s3a.multipart.threshold in [default..default*2],behavior
18,hadoop.caller.context.max.size,hadoop.caller.context.signature.max.size,hadoop.caller.context.max.size > 0 => hadoop.caller.context.signature.max.size > 0,behavior
19,hadoop.security.group.mapping.ldap.search.filter.group,hadoop.security.group.mapping.ldap.bind.user,hadoop.security.group.mapping.ldap.search.filter.group != null => hadoop.security.group.mapping.ldap.bind.user != null,behavior
20,seq.io.sort.mb,hbase.hregion.memstore.flush.size,seq.io.sort.mb > 100 => hbase.hregion.memstore.flush.size > 134217728,behavior
21,hadoop.security.group.mapping.ldap.search.filter.group,hadoop.security.group.mapping.ldap.url,hadoop.security.group.mapping.ldap.search.filter.group != null => hadoop.security.group.mapping.ldap.url != null,behavior
22,hadoop.tmp.dir,mapreduce.cluster.temp.dir,"hadoop.tmp.dir != null => mapreduce.cluster.temp.dir = hadoop.tmp.dir + ""/mapred""",behavior
23,fs.s3a.multipart.size,fs.s3a.block.size,fs.s3a.multipart.size > fs.s3a.block.size => fs.s3a.block.size = fs.s3a.multipart.size,behavior
24,fs.s3a.signing-algorithm,fs.s3a.connection.ssl.enabled,fs.s3a.signing-algorithm = 'AWS4-HMAC-SHA256' => fs.s3a.connection.ssl.enabled = true,behavior
25,fs.azure.saskey.usecontainersaskeyforallaccess,fs.azure.authorization.caching.enable,fs.azure.saskey.usecontainersaskeyforallaccess = true => fs.azure.authorization.caching.enable = true,behavior
26,fs.s3a.proxy.domain,fs.s3a.proxy.host,fs.s3a.proxy.domain != null => fs.s3a.proxy.host != null,behavior
27,io.mapfile.bloom.size,io.mapfile.bloom.error.rate,io.mapfile.bloom.error.rate < io.mapfile.bloom.size => io.mapfile.bloom.error.rate < io.mapfile.bloom.size,behavior
28,ssl.server.keystore.password,ssl.server.truststore.password,ssl.server.keystore.password != null => ssl.server.truststore.password != null,behavior
29,fs.s3a.connection.timeout,fs.s3a.connection.establishment.timeout,fs.s3a.connection.timeout = X => fs.s3a.connection.establishment.timeout = X * 0.5,behavior
30,datanode.https.port,datanode.http.port,datanode.https.port != null => datanode.http.port != null,behavior
31,hadoop.security.secure.random.impl,hadoop.security.random.device.file.path,hadoop.security.random.device.file.path != null => hadoop.security.secure.random.impl = ANY,behavior
32,s3.bytes-per-checksum,rgw_obj_stripe_size,s3.bytes-per-checksum > rgw_obj_stripe_size => s3.bytes-per-checksum <= rgw_obj_stripe_size,behavior
33,zookeeper.recovery.retry.maxsleeptime,hbase.zookeeper.property.tickTime,<Dependency> ::= <Variable> = <Singlevalue> => <Variable> = <Expression>,behavior
34,hadoop.security.group.mapping.ldap.connection.timeout.ms,hadoop.security.group.mapping.ldap.read.timeout.ms,hadoop.security.group.mapping.ldap.connection.timeout.ms > 0 => hadoop.security.group.mapping.ldap.read.timeout.ms > 0,behavior
35,hadoop.security.dns.interface,hadoop.security.dns.nameserver,hadoop.security.dns.interface != null => hadoop.security.dns.nameserver != null,control
36,hadoop.registry.system.acls,hadoop.security.authorization,hadoop.security.authorization = true => hadoop.registry.system.acls != null,control
37,hadoop.security.group.mapping.ldap.search.attr.member,hadoop.security.group.mapping.ldap.url,hadoop.security.group.mapping.ldap.url != null => hadoop.security.group.mapping.ldap.search.attr.member = ANY,control
38,hadoop.user.group.static.mapping.overrides,hadoop.security.authentication,"hadoop.security.authentication = ""kerberos"" => hadoop.user.group.static.mapping.overrides != null",control
39,hadoop.security.instrumentation.requires.admin,hadoop.security.authorization,hadoop.security.authorization = true => hadoop.security.instrumentation.requires.admin = true,control
40,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl.keystore.password.file,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.keystore.password.file != null,control
41,fs.s3a.max.total.tasks,fs.s3a.connection.maximum,fs.s3a.max.total.tasks > default => fs.s3a.connection.maximum > default,control
42,hadoop.http.authentication.token.validity,hadoop.http.authentication.kerberos.keytab,hadoop.http.authentication.kerberos.keytab != null => hadoop.http.authentication.token.validity = ANY,control
43,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl.keystore,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.keystore != null,control
44,fs.adl.oauth2.access.token.provider.type,fs.adl.oauth2.refresh.url,fs.adl.oauth2.access.token.provider.type != null => fs.adl.oauth2.refresh.url != null,control
45,hadoop.security.groups.cache.secs,hadoop.security.groups.cache.background.reload.threads,hadoop.security.groups.cache.background.reload = true => hadoop.security.groups.cache.background.reload.threads > 0,control
46,hadoop.zk.retry-interval-ms,ha.zookeeper.quorum,hadoop.zk.retry-interval-ms > 0 => ha.zookeeper.quorum != null,control
47,hadoop.http.authentication.token.validity,hadoop.http.authentication.signature.secret.file,hadoop.http.authentication.signature.secret.file != null => hadoop.http.authentication.token.validity = ANY,control
48,fs.azure.secure.mode,fs.azure.local.sas.key.mode,fs.azure.secure.mode = true => fs.azure.local.sas.key.mode != null,control
49,hadoop.security.group.mapping.ldap.search.group.hierarchy.levels,hadoop.security.group.mapping.ldap.base,hadoop.security.group.mapping.ldap.base != null => hadoop.security.group.mapping.ldap.search.group.hierarchy.levels = ANY,control
50,hadoop.http.cross-origin.allowed-origins,hadoop.http.cross-origin.enabled,hadoop.http.cross-origin.enabled = true => hadoop.http.cross-origin.allowed-origins != null,control
51,hadoop.security.authentication,hadoop.security.group.mapping,"hadoop.security.authentication = ""kerberos"" => hadoop.security.group.mapping = ""org.apache.hadoop.security.LdapGroupsMapping""",control
52,hadoop.security.group.mapping.ldap.search.attr.memberof,hadoop.security.group.mapping.ldap.url,hadoop.security.group.mapping.ldap.url != null => hadoop.security.group.mapping.ldap.search.attr.memberof != null,control
53,hadoop.security.authentication,hadoop.security.impersonation.provider.class,"hadoop.security.authentication = ""kerberos"" => hadoop.security.impersonation.provider.class != null",control
54,hadoop.http.cross-origin.max-age,hadoop.http.cross-origin.allowed-headers,hadoop.http.cross-origin.enabled = true => hadoop.http.cross-origin.max-age = ANY,control
55,hadoop.security.dns.log-slow-lookups.enabled,hadoop.security.dns.log-slow-lookups.threshold.ms,hadoop.security.dns.log-slow-lookups.enabled = true => hadoop.security.dns.log-slow-lookups.threshold.ms != null,control
56,hadoop.security.authorization,hadoop.security.authentication,"hadoop.security.authentication = ""kerberos"" => hadoop.security.authorization = ""true""",control
57,hfile.block.cache.size,hbase.bucketcache.size,"hfile.block.cache.size > 0.4 => hbase.bucketcache.size in {{0.2, 0.3, 0.4}}",control
58,hadoop.security.group.mapping.ldap.directory.search.timeout,hadoop.security.group.mapping,"hadoop.security.group.mapping = ""org.apache.hadoop.security.LdapGroupsMapping"" => hadoop.security.group.mapping.ldap.directory.search.timeout > 0",control
59,hadoop.security.group.mapping.ldap.search.filter.group,hadoop.security.group.mapping.ldap.base,hadoop.security.group.mapping.ldap.base != null => hadoop.security.group.mapping.ldap.search.filter.group = ANY,control
60,hadoop.security.dns.interface,hadoop.security.dns.nameserver,hadoop.security.dns.interface = ANY => hadoop.security.dns.nameserver = ANY,control
61,fs.s3a.proxy.domain,fs.s3a.proxy.port,fs.s3a.proxy.port != null => fs.s3a.proxy.domain != null,control
62,hadoop.ssl.enabled,hadoop.ssl.enabled.protocols,hadoop.ssl.enabled = true => hadoop.ssl.enabled.protocols != null,control
63,hadoop.caller.context.enabled,hadoop.caller.context.max.size,hadoop.caller.context.enabled = true => hadoop.caller.context.max.size = 128,control
64,net.topology.script.file.name,net.topology.node.switch.mapping.impl,net.topology.script.file.name != null => net.topology.node.switch.mapping.impl = org.apache.hadoop.net.ScriptBasedMapping,control
65,zookeeper.session.timeout,hbase.zookeeper.property.maxSessionTimeout,hbase.zookeeper.property.maxSessionTimeout = hbase.zookeeper.property.tickTime * N => zookeeper.session.timeout < hbase.zookeeper.property.maxSessionTimeout,control
66,ipc.client.low-latency,ipc.client.buffer-size,ipc.client.low-latency = true => ipc.client.buffer-size > default,control
67,hadoop.security.service.user.name.key,hadoop.security.authentication,"hadoop.security.authentication = ""kerberos"" => hadoop.security.service.user.name.key != null",control
68,ssl.server.truststore.location,dfs.datanode.https.address,dfs.datanode.https.address != null => ssl.server.truststore.location != null,control
69,ipc.client.rpc-timeout.ms,ipc.server.rpc-timeout.ms,ipc.client.rpc-timeout.ms > 0 => ipc.server.rpc-timeout.ms > 0,control
70,net.topology.script.file.name,dfs.namenode.reject-unresolved-dn-topology-mapping,net.topology.script.file.name = null => dfs.namenode.reject-unresolved-dn-topology-mapping = true,control
71,fs.s3a.fast.upload.buffer,fs.s3a.fast.upload,fs.s3a.fast.upload = true => fs.s3a.fast.upload.buffer = ANY,control
72,hadoop.security.authentication,hadoop.rpc.protection,"hadoop.security.authentication = ""kerberos"" => hadoop.rpc.protection = ""privacy""",control
73,hadoop.registry.rm.enabled,hadoop.registry.zk.retry.times,hadoop.registry.rm.enabled = true => hadoop.registry.zk.retry.times > 0,control
74,fs.adl.oauth2.access.token.provider.type,fs.adl.oauth2.credential,fs.adl.oauth2.access.token.provider.type != null => fs.adl.oauth2.credential != null,control
75,hadoop.security.group.mapping.ldap.ssl.keystore.password,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.keystore.password != null,control
76,fs.azure.authorization,hadoop.security.authorization,hadoop.security.authorization = true => fs.azure.authorization = true,control
77,hadoop.security.group.mapping.ldap.search.filter.user,hadoop.security.group.mapping.ldap.bind.user,hadoop.security.group.mapping.ldap.bind.user != null => hadoop.security.group.mapping.ldap.search.filter.user != null,control
78,hadoop.security.group.mapping.ldap.groupbase,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.groupbase != null,control
79,hadoop.rpc.protection,hadoop.ssl.enabled,"hadoop.ssl.enabled = ""true"" => hadoop.rpc.protection in {""privacy"", ""integrity""}",control
80,hadoop.security.group.mapping.ldap.ssl.truststore.password.file,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.truststore.password.file != null,control
81,hadoop.registry.zk.retry.times,hadoop.registry.zk.quorum,hadoop.registry.zk.retry.times > 0 => hadoop.registry.zk.quorum != null,control
82,fs.adl.oauth2.access.token.provider.type,fs.adl.oauth2.client.id,fs.adl.oauth2.access.token.provider.type != null => fs.adl.oauth2.client.id != null,control
83,hadoop.security.group.mapping.ldap.ssl.keystore.password.file,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.keystore.password.file != null,control
84,ipc.client.tcpnodelay,ipc.client.low-latency,ipc.client.tcpnodelay = true => ipc.client.low-latency = false,control
85,hadoop.security.group.mapping.ldap.ssl,hadoop.security.group.mapping.ldap.ssl.keystore.password,hadoop.security.group.mapping.ldap.ssl = true => hadoop.security.group.mapping.ldap.ssl.keystore.password != null,control
86,ssl.server.keystore.password,ssl.server.ssl.enabled,ssl.server.keystore.password != null => ssl.server.ssl.enabled = true,control
87,tfile.fs.output.buffer.size,io.file.buffer.size,io.file.buffer.size = ANY => tfile.fs.output.buffer.size = io.file.buffer.size,default
88,fs.ftp.host,fs.ftp.host.port,fs.ftp.host != null => fs.ftp.host.port = 21,default
89,ha.zookeeper.session-timeout.ms,hadoop.zk.timeout-ms,hadoop.zk.timeout-ms = ANY => ha.zookeeper.session-timeout.ms = hadoop.zk.timeout-ms,default
90,fs.adl.oauth2.client.id,fs.adl.oauth2.credential,fs.adl.oauth2.credential = null => fs.adl.oauth2.client.id = ANY,default
91,fs.s3a.proxy.host,fs.s3a.proxy.port,"fs.s3a.proxy.host != null => fs.s3a.proxy.port = {80, 443}",default
92,file.stream-buffer-size,io.file.buffer.size,io.file.buffer.size = ANY => file.stream-buffer-size = io.file.buffer.size,default
93,hadoop.security.crypto.jce.provider,hadoop.security.credential.provider.path,"hadoop.security.credential.provider.path = ""ANY"" => hadoop.security.crypto.jce.provider = ""ANY""",default
94,hadoop.socks.server,hadoop.rpc.socket.factory.class.default,hadoop.socks.server = null => hadoop.rpc.socket.factory.class.default = hadoop.rpc.socket.factory.class.default,default
95,hadoop.security.credstore.java-keystore-provider.password-file,hadoop.security.group.mapping.ldap.ssl.keystore.password,hadoop.security.credstore.java-keystore-provider.password-file = ANY => hadoop.security.group.mapping.ldap.ssl.keystore.password = hadoop.security.credstore.java-keystore-provider.password-file,default
96,hadoop.security.group.mapping.ldap.search.attr.member,hadoop.security.group.mapping.ldap.search.attr.memberof,hadoop.security.group.mapping.ldap.search.attr.member = ANY => hadoop.security.group.mapping.ldap.search.attr.memberof = member,default
97,io.seqfile.local.dir,hadoop.tmp.dir,hadoop.tmp.dir != null => io.seqfile.local.dir = hadoop.tmp.dir/seqfile,default
98,fs.s3a.aws.credentials.provider,fs.s3a.security.credential.provider.path,fs.s3a.aws.credentials.provider = null => fs.s3a.security.credential.provider.path != null,default
99,ssl.server.keystore.location,dfs.https.server.keystore.resource,"dfs.https.server.keystore.resource = null => ssl.server.keystore.location = ""ANY""",default
100,hadoop.ssl.keystores.factory.class,hadoop.ssl.client.conf,hadoop.ssl.client.conf = null => hadoop.ssl.keystores.factory.class = ANY,default
101,fs.s3.buffer.dir,hadoop.tmp.dir,hadoop.tmp.dir = ANY => fs.s3.buffer.dir = hadoop.tmp.dir,default
102,fs.s3a.access.key,fs.s3a.security.credential.provider.path,fs.s3a.access.key = null => fs.s3a.security.credential.provider.path != null,default
103,fs.s3a.session.token,fs.s3a.security.credential.provider.path,fs.s3a.security.credential.provider.path != null => fs.s3a.session.token = ANY,default
104,hadoop.security.secure.random.impl,hadoop.security.random.device.file.path,"hadoop.security.secure.random.impl = ANY => hadoop.security.random.device.file.path = ""/dev/urandom""",default
105,fs.adl.oauth2.client.id,fs.adl.oauth2.access.token.provider,"fs.adl.oauth2.access.token.provider = ""org.apache.hadoop.fs.adl.oauth2.ConfRefreshTokenBasedAccessTokenProvider"" => fs.adl.oauth2.client.id = ANY",default
106,hadoop.security.group.mapping.ldap.base,hadoop.security.group.mapping.ldap.userbase,hadoop.security.group.mapping.ldap.userbase = null => hadoop.security.group.mapping.ldap.base != null,default
107,hadoop.security.group.mapping.ldap.search.attr.group.name,hadoop.security.group.mapping.ldap.posix.attr.gid.name,hadoop.security.group.mapping.ldap.search.attr.group.name = ANY => hadoop.security.group.mapping.ldap.posix.attr.gid.name = hadoop.security.group.mapping.ldap.search.attr.group.name,default
108,s3.stream-buffer-size,io.file.buffer.size,io.file.buffer.size = ANY => s3.stream-buffer-size = io.file.buffer.size,default
109,fs.s3a.connection.ssl.enabled,fs.s3a.proxy.port,fs.s3a.connection.ssl.enabled = ANY => fs.s3a.proxy.port = 443,default
110,hadoop.security.group.mapping.ldap.ssl.keystore.password.file,hadoop.security.group.mapping.ldap.ssl.keystore.password,hadoop.security.group.mapping.ldap.ssl.keystore.password.file = ANY => hadoop.security.group.mapping.ldap.ssl.keystore.password = hadoop.security.group.mapping.ldap.ssl.keystore.password.file,default
111,ftp.bytes-per-checksum,io.bytes.per.checksum,ftp.bytes-per-checksum = ANY => io.bytes.per.checksum = ftp.bytes-per-checksum,default
112,hadoop.security.credstore.java-keystore-provider.password-file,hadoop.security.group.mapping.ldap.ssl.truststore.password.file,hadoop.security.credstore.java-keystore-provider.password-file = ANY => hadoop.security.group.mapping.ldap.ssl.truststore.password.file = hadoop.security.credstore.java-keystore-provider.password-file,default
113,fs.defaultFS,fs.default.name,fs.defaultFS = ANY => fs.default.name = fs.defaultFS,default
114,hadoop.security.group.mapping.ldap.bind.password,hadoop.security.group.mapping.ldap.bind.password.file,hadoop.security.group.mapping.ldap.bind.password != null => hadoop.security.group.mapping.ldap.bind.password.file = ANY,overwrite
115,ipc.client.ping,ipc.ping.interval,ipc.client.ping = true => ipc.ping.interval > 0,value
116,s3.bytes-per-checksum,s3native.bytes-per-checksum,s3native.bytes-per-checksum = s3.bytes-per-checksum,value
117,s3.bytes-per-checksum,s3.client-write-packet-size,s3.bytes-per-checksum < s3.client-write-packet-size,value
118,hadoop.ssl.enabled.protocols,hadoop.ssl.client.conf,"hadoop.ssl.client.conf in {TLSv1, TLSv1.1, TLSv1.2} => hadoop.ssl.enabled.protocols in {TLSv1, TLSv1.1, TLSv1.2}",value
119,zookeeper.session.timeout,hbase.lease.recovery.timeout,hbase.lease.recovery.timeout > zookeeper.session.timeout,value
120,s3native.stream-buffer-size,s3native.client-write-packet-size,s3native.stream-buffer-size > s3native.client-write-packet-size => s3native.client-write-packet-size < s3native.stream-buffer-size,value
121,ftp.client-write-packet-size,ftp.stream-buffer-size,ftp.client-write-packet-size > 0 => ftp.stream-buffer-size >= ftp.client-write-packet-size,value
122,hadoop.registry.zk.connection.timeout.ms,hadoop.registry.zk.retry.interval.ms,hadoop.registry.zk.retry.interval.ms < hadoop.registry.zk.connection.timeout.ms => hadoop.registry.zk.connection.timeout.ms > hadoop.registry.zk.retry.interval.ms,value
123,hadoop.security.group.mapping.providers,hadoop.security.group.mapping.ldap.url,"hadoop.security.group.mapping.ldap.url != """" => hadoop.security.group.mapping.providers in { ""org.apache.hadoop.security.LdapGroupsMapping"" }",value
124,ha.health-monitor.rpc-timeout.ms,ha.failover-controller.graceful-fence.rpc-timeout.ms,ha.failover-controller.graceful-fence.rpc-timeout.ms = ha.health-monitor.rpc-timeout.ms => ha.health-monitor.rpc-timeout.ms = ha.failover-controller.graceful-fence.rpc-timeout.ms,value
125,hadoop.ssl.client.conf,hadoop.ssl.server.conf,hadoop.ssl.server.conf = ANY => hadoop.ssl.client.conf = ANY,value
126,fs.s3a.proxy.host,fs.s3a.proxy.password,fs.s3a.proxy.host != null => fs.s3a.proxy.password != null,value
127,hadoop.security.group.mapping.ldap.search.attr.group.name,hadoop.security.group.mapping.ldap.search.filter.group,hadoop.security.group.mapping.ldap.search.filter.group != null => hadoop.security.group.mapping.ldap.search.attr.group.name != null,value
128,hadoop.security.crypto.buffer.size,io.file.buffer.size,io.file.buffer.size = hadoop.security.crypto.buffer.size,value
129,hadoop.security.groups.cache.secs,hadoop.security.groups.cache.warn.after.ms,hadoop.security.groups.cache.warn.after.ms = hadoop.security.groups.cache.secs * 1000,value
130,hadoop.security.group.mapping.ldap.connection.timeout.ms,hadoop.security.group.mapping.ldap.directory.search.timeout,hadoop.security.group.mapping.ldap.connection.timeout.ms < hadoop.security.group.mapping.ldap.directory.search.timeout,value
131,hadoop.ssl.enabled.protocols,hadoop.ssl.server.conf,"hadoop.ssl.server.conf in {TLSv1, TLSv1.1, TLSv1.2} => hadoop.ssl.enabled.protocols in {TLSv1, TLSv1.1, TLSv1.2}",value
132,file.bytes-per-checksum,file.client-write-packet-size,file.bytes-per-checksum < file.client-write-packet-size,value
133,hadoop.security.group.mapping.ldap.ssl.keystore,hadoop.security.group.mapping.ldap.ssl.keystore.password.file,hadoop.security.group.mapping.ldap.ssl.keystore != null => hadoop.security.group.mapping.ldap.ssl.keystore.password.file != null,value
134,hadoop.security.group.mapping.ldap.search.attr.memberof,hadoop.security.group.mapping.ldap.search.filter.group,hadoop.security.group.mapping.ldap.search.filter.group != null => hadoop.security.group.mapping.ldap.search.attr.memberof != null,value
135,file.bytes-per-checksum,io.bytes.per.checksum,file.bytes-per-checksum = io.bytes-per-checksum,value
136,hadoop.security.group.mapping,hadoop.security.group.mapping.ldap.url,hadoop.security.group.mapping = org.apache.hadoop.security.LdapGroupsMapping => hadoop.security.group.mapping.ldap.url != null,value
